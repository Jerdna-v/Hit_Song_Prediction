{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0912ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test Accuracy (80/20 Split) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>ExtraTrees</th>\n",
       "      <th>GradientBoosting</th>\n",
       "      <th>HistGradientBoosting</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>SGD</th>\n",
       "      <th>DecisionTree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dataset-of-00s</th>\n",
       "      <td>0.865532</td>\n",
       "      <td>0.853617</td>\n",
       "      <td>0.867234</td>\n",
       "      <td>0.864681</td>\n",
       "      <td>0.851915</td>\n",
       "      <td>0.506383</td>\n",
       "      <td>0.820426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-10s</th>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.835156</td>\n",
       "      <td>0.839844</td>\n",
       "      <td>0.846094</td>\n",
       "      <td>0.818750</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.798438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-60s</th>\n",
       "      <td>0.768652</td>\n",
       "      <td>0.769809</td>\n",
       "      <td>0.762290</td>\n",
       "      <td>0.775014</td>\n",
       "      <td>0.753036</td>\n",
       "      <td>0.500289</td>\n",
       "      <td>0.716599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-70s</th>\n",
       "      <td>0.765766</td>\n",
       "      <td>0.769627</td>\n",
       "      <td>0.767053</td>\n",
       "      <td>0.779279</td>\n",
       "      <td>0.756113</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.728443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-80s</th>\n",
       "      <td>0.808249</td>\n",
       "      <td>0.800289</td>\n",
       "      <td>0.810420</td>\n",
       "      <td>0.813314</td>\n",
       "      <td>0.786541</td>\n",
       "      <td>0.552822</td>\n",
       "      <td>0.742402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-90s</th>\n",
       "      <td>0.840580</td>\n",
       "      <td>0.834239</td>\n",
       "      <td>0.837862</td>\n",
       "      <td>0.842391</td>\n",
       "      <td>0.815217</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.800725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.788494</td>\n",
       "      <td>0.787643</td>\n",
       "      <td>0.785210</td>\n",
       "      <td>0.787886</td>\n",
       "      <td>0.759061</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.758696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                RandomForest  ExtraTrees  GradientBoosting  \\\n",
       "dataset-of-00s      0.865532    0.853617          0.867234   \n",
       "dataset-of-10s      0.850000    0.835156          0.839844   \n",
       "dataset-of-60s      0.768652    0.769809          0.762290   \n",
       "dataset-of-70s      0.765766    0.769627          0.767053   \n",
       "dataset-of-80s      0.808249    0.800289          0.810420   \n",
       "dataset-of-90s      0.840580    0.834239          0.837862   \n",
       "Overall             0.788494    0.787643          0.785210   \n",
       "\n",
       "                HistGradientBoosting  AdaBoost       SGD  DecisionTree  \n",
       "dataset-of-00s              0.864681  0.851915  0.506383      0.820426  \n",
       "dataset-of-10s              0.846094  0.818750  0.500000      0.798438  \n",
       "dataset-of-60s              0.775014  0.753036  0.500289      0.716599  \n",
       "dataset-of-70s              0.779279  0.756113  0.500000      0.728443  \n",
       "dataset-of-80s              0.813314  0.786541  0.552822      0.742402  \n",
       "dataset-of-90s              0.842391  0.815217  0.500000      0.800725  \n",
       "Overall                     0.787886  0.759061  0.500000      0.758696  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Test F1-Score (80/20 Split) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>ExtraTrees</th>\n",
       "      <th>GradientBoosting</th>\n",
       "      <th>HistGradientBoosting</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>SGD</th>\n",
       "      <th>DecisionTree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dataset-of-00s</th>\n",
       "      <td>0.870915</td>\n",
       "      <td>0.863492</td>\n",
       "      <td>0.873786</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.859451</td>\n",
       "      <td>0.669327</td>\n",
       "      <td>0.828873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-10s</th>\n",
       "      <td>0.855856</td>\n",
       "      <td>0.847212</td>\n",
       "      <td>0.846212</td>\n",
       "      <td>0.853313</td>\n",
       "      <td>0.830657</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.809735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-60s</th>\n",
       "      <td>0.785638</td>\n",
       "      <td>0.787166</td>\n",
       "      <td>0.780096</td>\n",
       "      <td>0.791644</td>\n",
       "      <td>0.775853</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.737124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-70s</th>\n",
       "      <td>0.784615</td>\n",
       "      <td>0.788666</td>\n",
       "      <td>0.783751</td>\n",
       "      <td>0.792247</td>\n",
       "      <td>0.770720</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.753216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-80s</th>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.815754</td>\n",
       "      <td>0.818308</td>\n",
       "      <td>0.821330</td>\n",
       "      <td>0.798635</td>\n",
       "      <td>0.667742</td>\n",
       "      <td>0.757493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-90s</th>\n",
       "      <td>0.848797</td>\n",
       "      <td>0.841558</td>\n",
       "      <td>0.846088</td>\n",
       "      <td>0.848958</td>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.809028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.800639</td>\n",
       "      <td>0.798402</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.774912</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.776072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                RandomForest  ExtraTrees  GradientBoosting  \\\n",
       "dataset-of-00s      0.870915    0.863492          0.873786   \n",
       "dataset-of-10s      0.855856    0.847212          0.846212   \n",
       "dataset-of-60s      0.785638    0.787166          0.780096   \n",
       "dataset-of-70s      0.784615    0.788666          0.783751   \n",
       "dataset-of-80s      0.814815    0.815754          0.818308   \n",
       "dataset-of-90s      0.848797    0.841558          0.846088   \n",
       "Overall             0.801325    0.800639          0.798402   \n",
       "\n",
       "                HistGradientBoosting  AdaBoost       SGD  DecisionTree  \n",
       "dataset-of-00s              0.869565  0.859451  0.669327      0.828873  \n",
       "dataset-of-10s              0.853313  0.830657  0.666667      0.809735  \n",
       "dataset-of-60s              0.791644  0.775853  0.000000      0.737124  \n",
       "dataset-of-70s              0.792247  0.770720  0.666667      0.753216  \n",
       "dataset-of-80s              0.821330  0.798635  0.667742      0.757493  \n",
       "dataset-of-90s              0.848958  0.825939  0.000000      0.809028  \n",
       "Overall                     0.800183  0.774912  0.000000      0.776072  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Test Accuracy (70/30 Split) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>ExtraTrees</th>\n",
       "      <th>GradientBoosting</th>\n",
       "      <th>HistGradientBoosting</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>SGD</th>\n",
       "      <th>DecisionTree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dataset-of-00s</th>\n",
       "      <td>0.863791</td>\n",
       "      <td>0.862656</td>\n",
       "      <td>0.867764</td>\n",
       "      <td>0.872304</td>\n",
       "      <td>0.857548</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.813848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-10s</th>\n",
       "      <td>0.843229</td>\n",
       "      <td>0.840625</td>\n",
       "      <td>0.842187</td>\n",
       "      <td>0.839583</td>\n",
       "      <td>0.818750</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.794792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-60s</th>\n",
       "      <td>0.768608</td>\n",
       "      <td>0.763980</td>\n",
       "      <td>0.770150</td>\n",
       "      <td>0.769765</td>\n",
       "      <td>0.758966</td>\n",
       "      <td>0.499807</td>\n",
       "      <td>0.719630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-70s</th>\n",
       "      <td>0.772532</td>\n",
       "      <td>0.781974</td>\n",
       "      <td>0.774249</td>\n",
       "      <td>0.778112</td>\n",
       "      <td>0.749356</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.708155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-80s</th>\n",
       "      <td>0.794501</td>\n",
       "      <td>0.793054</td>\n",
       "      <td>0.800289</td>\n",
       "      <td>0.806561</td>\n",
       "      <td>0.775687</td>\n",
       "      <td>0.499759</td>\n",
       "      <td>0.751085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-90s</th>\n",
       "      <td>0.849034</td>\n",
       "      <td>0.842995</td>\n",
       "      <td>0.852053</td>\n",
       "      <td>0.846618</td>\n",
       "      <td>0.820048</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.785628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.787788</td>\n",
       "      <td>0.780895</td>\n",
       "      <td>0.784706</td>\n",
       "      <td>0.785274</td>\n",
       "      <td>0.762326</td>\n",
       "      <td>0.496675</td>\n",
       "      <td>0.755595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                RandomForest  ExtraTrees  GradientBoosting  \\\n",
       "dataset-of-00s      0.863791    0.862656          0.867764   \n",
       "dataset-of-10s      0.843229    0.840625          0.842187   \n",
       "dataset-of-60s      0.768608    0.763980          0.770150   \n",
       "dataset-of-70s      0.772532    0.781974          0.774249   \n",
       "dataset-of-80s      0.794501    0.793054          0.800289   \n",
       "dataset-of-90s      0.849034    0.842995          0.852053   \n",
       "Overall             0.787788    0.780895          0.784706   \n",
       "\n",
       "                HistGradientBoosting  AdaBoost       SGD  DecisionTree  \n",
       "dataset-of-00s              0.872304  0.857548  0.500000      0.813848  \n",
       "dataset-of-10s              0.839583  0.818750  0.500000      0.794792  \n",
       "dataset-of-60s              0.769765  0.758966  0.499807      0.719630  \n",
       "dataset-of-70s              0.778112  0.749356  0.500000      0.708155  \n",
       "dataset-of-80s              0.806561  0.775687  0.499759      0.751085  \n",
       "dataset-of-90s              0.846618  0.820048  0.500000      0.785628  \n",
       "Overall                     0.785274  0.762326  0.496675      0.755595  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Test F1-Score (70/30 Split) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>ExtraTrees</th>\n",
       "      <th>GradientBoosting</th>\n",
       "      <th>HistGradientBoosting</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>SGD</th>\n",
       "      <th>DecisionTree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dataset-of-00s</th>\n",
       "      <td>0.868132</td>\n",
       "      <td>0.870172</td>\n",
       "      <td>0.873025</td>\n",
       "      <td>0.877250</td>\n",
       "      <td>0.865416</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.823845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-10s</th>\n",
       "      <td>0.848057</td>\n",
       "      <td>0.851022</td>\n",
       "      <td>0.848272</td>\n",
       "      <td>0.843972</td>\n",
       "      <td>0.825126</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.802605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-60s</th>\n",
       "      <td>0.791522</td>\n",
       "      <td>0.786462</td>\n",
       "      <td>0.788352</td>\n",
       "      <td>0.787620</td>\n",
       "      <td>0.781086</td>\n",
       "      <td>0.666495</td>\n",
       "      <td>0.744104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-70s</th>\n",
       "      <td>0.791830</td>\n",
       "      <td>0.799368</td>\n",
       "      <td>0.788415</td>\n",
       "      <td>0.788548</td>\n",
       "      <td>0.766773</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.728868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-80s</th>\n",
       "      <td>0.806364</td>\n",
       "      <td>0.808738</td>\n",
       "      <td>0.807978</td>\n",
       "      <td>0.815462</td>\n",
       "      <td>0.787185</td>\n",
       "      <td>0.666452</td>\n",
       "      <td>0.770053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-90s</th>\n",
       "      <td>0.857306</td>\n",
       "      <td>0.851429</td>\n",
       "      <td>0.858952</td>\n",
       "      <td>0.854023</td>\n",
       "      <td>0.829519</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.792033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.800761</td>\n",
       "      <td>0.799525</td>\n",
       "      <td>0.798451</td>\n",
       "      <td>0.797739</td>\n",
       "      <td>0.776174</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.774300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                RandomForest  ExtraTrees  GradientBoosting  \\\n",
       "dataset-of-00s      0.868132    0.870172          0.873025   \n",
       "dataset-of-10s      0.848057    0.851022          0.848272   \n",
       "dataset-of-60s      0.791522    0.786462          0.788352   \n",
       "dataset-of-70s      0.791830    0.799368          0.788415   \n",
       "dataset-of-80s      0.806364    0.808738          0.807978   \n",
       "dataset-of-90s      0.857306    0.851429          0.858952   \n",
       "Overall             0.800761    0.799525          0.798451   \n",
       "\n",
       "                HistGradientBoosting  AdaBoost       SGD  DecisionTree  \n",
       "dataset-of-00s              0.877250  0.865416  0.666667      0.823845  \n",
       "dataset-of-10s              0.843972  0.825126  0.000000      0.802605  \n",
       "dataset-of-60s              0.787620  0.781086  0.666495      0.744104  \n",
       "dataset-of-70s              0.788548  0.766773  0.000000      0.728868  \n",
       "dataset-of-80s              0.815462  0.787185  0.666452      0.770053  \n",
       "dataset-of-90s              0.854023  0.829519  0.000000      0.792033  \n",
       "Overall                     0.797739  0.776174  0.000000      0.774300  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Best Model per Decade (80/20) by Test F1 ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Best Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dataset-of-00s</th>\n",
       "      <td>GradientBoosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-10s</th>\n",
       "      <td>RandomForest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-60s</th>\n",
       "      <td>HistGradientBoosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-70s</th>\n",
       "      <td>HistGradientBoosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-80s</th>\n",
       "      <td>HistGradientBoosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-90s</th>\n",
       "      <td>HistGradientBoosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>RandomForest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Best Model\n",
       "dataset-of-00s      GradientBoosting\n",
       "dataset-of-10s          RandomForest\n",
       "dataset-of-60s  HistGradientBoosting\n",
       "dataset-of-70s  HistGradientBoosting\n",
       "dataset-of-80s  HistGradientBoosting\n",
       "dataset-of-90s  HistGradientBoosting\n",
       "Overall                 RandomForest"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Best Model per Decade (70/30) by Test F1 ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Best Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dataset-of-00s</th>\n",
       "      <td>HistGradientBoosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-10s</th>\n",
       "      <td>ExtraTrees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-60s</th>\n",
       "      <td>RandomForest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-70s</th>\n",
       "      <td>ExtraTrees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-80s</th>\n",
       "      <td>HistGradientBoosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-90s</th>\n",
       "      <td>GradientBoosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>RandomForest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Best Model\n",
       "dataset-of-00s  HistGradientBoosting\n",
       "dataset-of-10s            ExtraTrees\n",
       "dataset-of-60s          RandomForest\n",
       "dataset-of-70s            ExtraTrees\n",
       "dataset-of-80s  HistGradientBoosting\n",
       "dataset-of-90s      GradientBoosting\n",
       "Overall                 RandomForest"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Mean CV F1 (5-Fold) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>ExtraTrees</th>\n",
       "      <th>GradientBoosting</th>\n",
       "      <th>HistGradientBoosting</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>SGD</th>\n",
       "      <th>DecisionTree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dataset-of-00s</th>\n",
       "      <td>0.860906</td>\n",
       "      <td>0.863578</td>\n",
       "      <td>0.861152</td>\n",
       "      <td>0.861622</td>\n",
       "      <td>0.855011</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.821057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-10s</th>\n",
       "      <td>0.854895</td>\n",
       "      <td>0.855027</td>\n",
       "      <td>0.851263</td>\n",
       "      <td>0.852251</td>\n",
       "      <td>0.840285</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.816993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-60s</th>\n",
       "      <td>0.792438</td>\n",
       "      <td>0.788104</td>\n",
       "      <td>0.792316</td>\n",
       "      <td>0.795198</td>\n",
       "      <td>0.779176</td>\n",
       "      <td>0.480340</td>\n",
       "      <td>0.754498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-70s</th>\n",
       "      <td>0.790769</td>\n",
       "      <td>0.788864</td>\n",
       "      <td>0.789756</td>\n",
       "      <td>0.790014</td>\n",
       "      <td>0.769568</td>\n",
       "      <td>0.533276</td>\n",
       "      <td>0.751590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-80s</th>\n",
       "      <td>0.813225</td>\n",
       "      <td>0.816020</td>\n",
       "      <td>0.812422</td>\n",
       "      <td>0.814759</td>\n",
       "      <td>0.800283</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.767660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-90s</th>\n",
       "      <td>0.855210</td>\n",
       "      <td>0.856834</td>\n",
       "      <td>0.857374</td>\n",
       "      <td>0.855053</td>\n",
       "      <td>0.842973</td>\n",
       "      <td>0.400977</td>\n",
       "      <td>0.812869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.800848</td>\n",
       "      <td>0.800155</td>\n",
       "      <td>0.797289</td>\n",
       "      <td>0.798035</td>\n",
       "      <td>0.776668</td>\n",
       "      <td>0.406232</td>\n",
       "      <td>0.772833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                RandomForest  ExtraTrees  GradientBoosting  \\\n",
       "dataset-of-00s      0.860906    0.863578          0.861152   \n",
       "dataset-of-10s      0.854895    0.855027          0.851263   \n",
       "dataset-of-60s      0.792438    0.788104          0.792316   \n",
       "dataset-of-70s      0.790769    0.788864          0.789756   \n",
       "dataset-of-80s      0.813225    0.816020          0.812422   \n",
       "dataset-of-90s      0.855210    0.856834          0.857374   \n",
       "Overall             0.800848    0.800155          0.797289   \n",
       "\n",
       "                HistGradientBoosting  AdaBoost       SGD  DecisionTree  \n",
       "dataset-of-00s              0.861622  0.855011  0.400000      0.821057  \n",
       "dataset-of-10s              0.852251  0.840285  0.533333      0.816993  \n",
       "dataset-of-60s              0.795198  0.779176  0.480340      0.754498  \n",
       "dataset-of-70s              0.790014  0.769568  0.533276      0.751590  \n",
       "dataset-of-80s              0.814759  0.800283  0.666667      0.767660  \n",
       "dataset-of-90s              0.855053  0.842973  0.400977      0.812869  \n",
       "Overall                     0.798035  0.776668  0.406232      0.772833  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Mean CV F1 (10-Fold) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>ExtraTrees</th>\n",
       "      <th>GradientBoosting</th>\n",
       "      <th>HistGradientBoosting</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>SGD</th>\n",
       "      <th>DecisionTree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dataset-of-00s</th>\n",
       "      <td>0.860852</td>\n",
       "      <td>0.865779</td>\n",
       "      <td>0.861671</td>\n",
       "      <td>0.861437</td>\n",
       "      <td>0.853898</td>\n",
       "      <td>0.400075</td>\n",
       "      <td>0.819746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-10s</th>\n",
       "      <td>0.854051</td>\n",
       "      <td>0.856132</td>\n",
       "      <td>0.852708</td>\n",
       "      <td>0.854921</td>\n",
       "      <td>0.839568</td>\n",
       "      <td>0.281538</td>\n",
       "      <td>0.814722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-60s</th>\n",
       "      <td>0.791685</td>\n",
       "      <td>0.788283</td>\n",
       "      <td>0.789810</td>\n",
       "      <td>0.793472</td>\n",
       "      <td>0.778688</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.752912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-70s</th>\n",
       "      <td>0.793585</td>\n",
       "      <td>0.788009</td>\n",
       "      <td>0.789661</td>\n",
       "      <td>0.789338</td>\n",
       "      <td>0.768270</td>\n",
       "      <td>0.399943</td>\n",
       "      <td>0.751151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-80s</th>\n",
       "      <td>0.814781</td>\n",
       "      <td>0.814470</td>\n",
       "      <td>0.814014</td>\n",
       "      <td>0.819776</td>\n",
       "      <td>0.798628</td>\n",
       "      <td>0.308677</td>\n",
       "      <td>0.767991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-90s</th>\n",
       "      <td>0.856524</td>\n",
       "      <td>0.857638</td>\n",
       "      <td>0.856592</td>\n",
       "      <td>0.858817</td>\n",
       "      <td>0.841671</td>\n",
       "      <td>0.334397</td>\n",
       "      <td>0.818502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.801963</td>\n",
       "      <td>0.801580</td>\n",
       "      <td>0.796841</td>\n",
       "      <td>0.799406</td>\n",
       "      <td>0.776210</td>\n",
       "      <td>0.451940</td>\n",
       "      <td>0.774952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                RandomForest  ExtraTrees  GradientBoosting  \\\n",
       "dataset-of-00s      0.860852    0.865779          0.861671   \n",
       "dataset-of-10s      0.854051    0.856132          0.852708   \n",
       "dataset-of-60s      0.791685    0.788283          0.789810   \n",
       "dataset-of-70s      0.793585    0.788009          0.789661   \n",
       "dataset-of-80s      0.814781    0.814470          0.814014   \n",
       "dataset-of-90s      0.856524    0.857638          0.856592   \n",
       "Overall             0.801963    0.801580          0.796841   \n",
       "\n",
       "                HistGradientBoosting  AdaBoost       SGD  DecisionTree  \n",
       "dataset-of-00s              0.861437  0.853898  0.400075      0.819746  \n",
       "dataset-of-10s              0.854921  0.839568  0.281538      0.814722  \n",
       "dataset-of-60s              0.793472  0.778688  0.466667      0.752912  \n",
       "dataset-of-70s              0.789338  0.768270  0.399943      0.751151  \n",
       "dataset-of-80s              0.819776  0.798628  0.308677      0.767991  \n",
       "dataset-of-90s              0.858817  0.841671  0.334397      0.818502  \n",
       "Overall                     0.799406  0.776210  0.451940      0.774952  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Best Model per Decade (5-Fold CV) by Mean F1 ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Best Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dataset-of-00s</th>\n",
       "      <td>ExtraTrees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-10s</th>\n",
       "      <td>ExtraTrees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-60s</th>\n",
       "      <td>HistGradientBoosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-70s</th>\n",
       "      <td>RandomForest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-80s</th>\n",
       "      <td>ExtraTrees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-90s</th>\n",
       "      <td>GradientBoosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>RandomForest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Best Model\n",
       "dataset-of-00s            ExtraTrees\n",
       "dataset-of-10s            ExtraTrees\n",
       "dataset-of-60s  HistGradientBoosting\n",
       "dataset-of-70s          RandomForest\n",
       "dataset-of-80s            ExtraTrees\n",
       "dataset-of-90s      GradientBoosting\n",
       "Overall                 RandomForest"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Best Model per Decade (10-Fold CV) by Mean F1 ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Best Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dataset-of-00s</th>\n",
       "      <td>ExtraTrees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-10s</th>\n",
       "      <td>ExtraTrees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-60s</th>\n",
       "      <td>HistGradientBoosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-70s</th>\n",
       "      <td>RandomForest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-80s</th>\n",
       "      <td>HistGradientBoosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-90s</th>\n",
       "      <td>HistGradientBoosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>RandomForest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Best Model\n",
       "dataset-of-00s            ExtraTrees\n",
       "dataset-of-10s            ExtraTrees\n",
       "dataset-of-60s  HistGradientBoosting\n",
       "dataset-of-70s          RandomForest\n",
       "dataset-of-80s  HistGradientBoosting\n",
       "dataset-of-90s  HistGradientBoosting\n",
       "Overall                 RandomForest"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Best Hyperparameters (80/20 Split) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>ExtraTrees</th>\n",
       "      <th>GradientBoosting</th>\n",
       "      <th>HistGradientBoosting</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>SGD</th>\n",
       "      <th>DecisionTree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dataset-of-00s</th>\n",
       "      <td>{'max_depth': None, 'min_samples_split': 5, 'n...</td>\n",
       "      <td>{'max_depth': 20, 'min_samples_split': 5, 'n_e...</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 3, 'n_esti...</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': None, 'ma...</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 100}</td>\n",
       "      <td>{'alpha': 0.0001, 'penalty': 'l1'}</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-10s</th>\n",
       "      <td>{'max_depth': None, 'min_samples_split': 5, 'n...</td>\n",
       "      <td>{'max_depth': None, 'min_samples_split': 5, 'n...</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 10, 'max_...</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 100}</td>\n",
       "      <td>{'alpha': 0.01, 'penalty': 'l1'}</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-60s</th>\n",
       "      <td>{'max_depth': 20, 'min_samples_split': 2, 'n_e...</td>\n",
       "      <td>{'max_depth': None, 'min_samples_split': 5, 'n...</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 10, 'max_...</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 100}</td>\n",
       "      <td>{'alpha': 0.0001, 'penalty': 'l2'}</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-70s</th>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 2, 'n_e...</td>\n",
       "      <td>{'max_depth': 20, 'min_samples_split': 2, 'n_e...</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 10, 'max_...</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 100}</td>\n",
       "      <td>{'alpha': 0.0001, 'penalty': 'l1'}</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-80s</th>\n",
       "      <td>{'max_depth': 20, 'min_samples_split': 2, 'n_e...</td>\n",
       "      <td>{'max_depth': 20, 'min_samples_split': 2, 'n_e...</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 10, 'max_i...</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 100}</td>\n",
       "      <td>{'alpha': 0.01, 'penalty': 'l1'}</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-90s</th>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 2, 'n_e...</td>\n",
       "      <td>{'max_depth': None, 'min_samples_split': 5, 'n...</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': None, 'ma...</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 100}</td>\n",
       "      <td>{'alpha': 0.0001, 'penalty': 'l2'}</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>{'max_depth': 20, 'min_samples_split': 2, 'n_e...</td>\n",
       "      <td>{'max_depth': None, 'min_samples_split': 2, 'n...</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 10, 'max_i...</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 100}</td>\n",
       "      <td>{'alpha': 0.0001, 'penalty': 'l2'}</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 2}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     RandomForest  \\\n",
       "dataset-of-00s  {'max_depth': None, 'min_samples_split': 5, 'n...   \n",
       "dataset-of-10s  {'max_depth': None, 'min_samples_split': 5, 'n...   \n",
       "dataset-of-60s  {'max_depth': 20, 'min_samples_split': 2, 'n_e...   \n",
       "dataset-of-70s  {'max_depth': 10, 'min_samples_split': 2, 'n_e...   \n",
       "dataset-of-80s  {'max_depth': 20, 'min_samples_split': 2, 'n_e...   \n",
       "dataset-of-90s  {'max_depth': 10, 'min_samples_split': 2, 'n_e...   \n",
       "Overall         {'max_depth': 20, 'min_samples_split': 2, 'n_e...   \n",
       "\n",
       "                                                       ExtraTrees  \\\n",
       "dataset-of-00s  {'max_depth': 20, 'min_samples_split': 5, 'n_e...   \n",
       "dataset-of-10s  {'max_depth': None, 'min_samples_split': 5, 'n...   \n",
       "dataset-of-60s  {'max_depth': None, 'min_samples_split': 5, 'n...   \n",
       "dataset-of-70s  {'max_depth': 20, 'min_samples_split': 2, 'n_e...   \n",
       "dataset-of-80s  {'max_depth': 20, 'min_samples_split': 2, 'n_e...   \n",
       "dataset-of-90s  {'max_depth': None, 'min_samples_split': 5, 'n...   \n",
       "Overall         {'max_depth': None, 'min_samples_split': 2, 'n...   \n",
       "\n",
       "                                                 GradientBoosting  \\\n",
       "dataset-of-00s  {'learning_rate': 0.1, 'max_depth': 3, 'n_esti...   \n",
       "dataset-of-10s  {'learning_rate': 0.1, 'max_depth': 5, 'n_esti...   \n",
       "dataset-of-60s  {'learning_rate': 0.05, 'max_depth': 5, 'n_est...   \n",
       "dataset-of-70s  {'learning_rate': 0.05, 'max_depth': 5, 'n_est...   \n",
       "dataset-of-80s  {'learning_rate': 0.05, 'max_depth': 5, 'n_est...   \n",
       "dataset-of-90s  {'learning_rate': 0.05, 'max_depth': 3, 'n_est...   \n",
       "Overall         {'learning_rate': 0.1, 'max_depth': 5, 'n_esti...   \n",
       "\n",
       "                                             HistGradientBoosting  \\\n",
       "dataset-of-00s  {'learning_rate': 0.05, 'max_depth': None, 'ma...   \n",
       "dataset-of-10s  {'learning_rate': 0.05, 'max_depth': 10, 'max_...   \n",
       "dataset-of-60s  {'learning_rate': 0.05, 'max_depth': 10, 'max_...   \n",
       "dataset-of-70s  {'learning_rate': 0.05, 'max_depth': 10, 'max_...   \n",
       "dataset-of-80s  {'learning_rate': 0.1, 'max_depth': 10, 'max_i...   \n",
       "dataset-of-90s  {'learning_rate': 0.05, 'max_depth': None, 'ma...   \n",
       "Overall         {'learning_rate': 0.1, 'max_depth': 10, 'max_i...   \n",
       "\n",
       "                                                   AdaBoost  \\\n",
       "dataset-of-00s  {'learning_rate': 0.5, 'n_estimators': 100}   \n",
       "dataset-of-10s  {'learning_rate': 0.5, 'n_estimators': 100}   \n",
       "dataset-of-60s  {'learning_rate': 0.5, 'n_estimators': 100}   \n",
       "dataset-of-70s  {'learning_rate': 0.5, 'n_estimators': 100}   \n",
       "dataset-of-80s  {'learning_rate': 0.5, 'n_estimators': 100}   \n",
       "dataset-of-90s  {'learning_rate': 0.5, 'n_estimators': 100}   \n",
       "Overall         {'learning_rate': 0.5, 'n_estimators': 100}   \n",
       "\n",
       "                                               SGD  \\\n",
       "dataset-of-00s  {'alpha': 0.0001, 'penalty': 'l1'}   \n",
       "dataset-of-10s    {'alpha': 0.01, 'penalty': 'l1'}   \n",
       "dataset-of-60s  {'alpha': 0.0001, 'penalty': 'l2'}   \n",
       "dataset-of-70s  {'alpha': 0.0001, 'penalty': 'l1'}   \n",
       "dataset-of-80s    {'alpha': 0.01, 'penalty': 'l1'}   \n",
       "dataset-of-90s  {'alpha': 0.0001, 'penalty': 'l2'}   \n",
       "Overall         {'alpha': 0.0001, 'penalty': 'l2'}   \n",
       "\n",
       "                                             DecisionTree  \n",
       "dataset-of-00s  {'max_depth': 10, 'min_samples_split': 5}  \n",
       "dataset-of-10s  {'max_depth': 10, 'min_samples_split': 5}  \n",
       "dataset-of-60s  {'max_depth': 10, 'min_samples_split': 2}  \n",
       "dataset-of-70s  {'max_depth': 10, 'min_samples_split': 5}  \n",
       "dataset-of-80s  {'max_depth': 10, 'min_samples_split': 5}  \n",
       "dataset-of-90s  {'max_depth': 10, 'min_samples_split': 2}  \n",
       "Overall         {'max_depth': 10, 'min_samples_split': 2}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Best Hyperparameters (70/30 Split) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>ExtraTrees</th>\n",
       "      <th>GradientBoosting</th>\n",
       "      <th>HistGradientBoosting</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>SGD</th>\n",
       "      <th>DecisionTree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dataset-of-00s</th>\n",
       "      <td>{'max_depth': 20, 'min_samples_split': 2, 'n_e...</td>\n",
       "      <td>{'max_depth': None, 'min_samples_split': 5, 'n...</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 3, 'n_esti...</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': None, 'ma...</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 100}</td>\n",
       "      <td>{'alpha': 0.01, 'penalty': 'l1'}</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-10s</th>\n",
       "      <td>{'max_depth': None, 'min_samples_split': 2, 'n...</td>\n",
       "      <td>{'max_depth': None, 'min_samples_split': 2, 'n...</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 10, 'max_i...</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 100}</td>\n",
       "      <td>{'alpha': 0.01, 'penalty': 'l1'}</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-60s</th>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 2, 'n_e...</td>\n",
       "      <td>{'max_depth': 20, 'min_samples_split': 2, 'n_e...</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 10, 'max_...</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 100}</td>\n",
       "      <td>{'alpha': 0.0001, 'penalty': 'l1'}</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-70s</th>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 5, 'n_e...</td>\n",
       "      <td>{'max_depth': 20, 'min_samples_split': 2, 'n_e...</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 3, 'n_esti...</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 10, 'max_...</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 50}</td>\n",
       "      <td>{'alpha': 0.0001, 'penalty': 'l2'}</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-80s</th>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 2, 'n_e...</td>\n",
       "      <td>{'max_depth': 20, 'min_samples_split': 2, 'n_e...</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 10, 'max_...</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 100}</td>\n",
       "      <td>{'alpha': 0.01, 'penalty': 'l1'}</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-90s</th>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 5, 'n_e...</td>\n",
       "      <td>{'max_depth': 20, 'min_samples_split': 2, 'n_e...</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 3, 'n_esti...</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': None, 'ma...</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 50}</td>\n",
       "      <td>{'alpha': 0.01, 'penalty': 'l1'}</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>{'max_depth': 20, 'min_samples_split': 2, 'n_e...</td>\n",
       "      <td>{'max_depth': 20, 'min_samples_split': 2, 'n_e...</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 10, 'max_...</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 100}</td>\n",
       "      <td>{'alpha': 0.001, 'penalty': 'l2'}</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 2}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     RandomForest  \\\n",
       "dataset-of-00s  {'max_depth': 20, 'min_samples_split': 2, 'n_e...   \n",
       "dataset-of-10s  {'max_depth': None, 'min_samples_split': 2, 'n...   \n",
       "dataset-of-60s  {'max_depth': 10, 'min_samples_split': 2, 'n_e...   \n",
       "dataset-of-70s  {'max_depth': 10, 'min_samples_split': 5, 'n_e...   \n",
       "dataset-of-80s  {'max_depth': 10, 'min_samples_split': 2, 'n_e...   \n",
       "dataset-of-90s  {'max_depth': 10, 'min_samples_split': 5, 'n_e...   \n",
       "Overall         {'max_depth': 20, 'min_samples_split': 2, 'n_e...   \n",
       "\n",
       "                                                       ExtraTrees  \\\n",
       "dataset-of-00s  {'max_depth': None, 'min_samples_split': 5, 'n...   \n",
       "dataset-of-10s  {'max_depth': None, 'min_samples_split': 2, 'n...   \n",
       "dataset-of-60s  {'max_depth': 20, 'min_samples_split': 2, 'n_e...   \n",
       "dataset-of-70s  {'max_depth': 20, 'min_samples_split': 2, 'n_e...   \n",
       "dataset-of-80s  {'max_depth': 20, 'min_samples_split': 2, 'n_e...   \n",
       "dataset-of-90s  {'max_depth': 20, 'min_samples_split': 2, 'n_e...   \n",
       "Overall         {'max_depth': 20, 'min_samples_split': 2, 'n_e...   \n",
       "\n",
       "                                                 GradientBoosting  \\\n",
       "dataset-of-00s  {'learning_rate': 0.1, 'max_depth': 3, 'n_esti...   \n",
       "dataset-of-10s  {'learning_rate': 0.05, 'max_depth': 5, 'n_est...   \n",
       "dataset-of-60s  {'learning_rate': 0.05, 'max_depth': 5, 'n_est...   \n",
       "dataset-of-70s  {'learning_rate': 0.1, 'max_depth': 3, 'n_esti...   \n",
       "dataset-of-80s  {'learning_rate': 0.1, 'max_depth': 5, 'n_esti...   \n",
       "dataset-of-90s  {'learning_rate': 0.1, 'max_depth': 3, 'n_esti...   \n",
       "Overall         {'learning_rate': 0.1, 'max_depth': 5, 'n_esti...   \n",
       "\n",
       "                                             HistGradientBoosting  \\\n",
       "dataset-of-00s  {'learning_rate': 0.05, 'max_depth': None, 'ma...   \n",
       "dataset-of-10s  {'learning_rate': 0.1, 'max_depth': 10, 'max_i...   \n",
       "dataset-of-60s  {'learning_rate': 0.05, 'max_depth': 10, 'max_...   \n",
       "dataset-of-70s  {'learning_rate': 0.05, 'max_depth': 10, 'max_...   \n",
       "dataset-of-80s  {'learning_rate': 0.05, 'max_depth': 10, 'max_...   \n",
       "dataset-of-90s  {'learning_rate': 0.05, 'max_depth': None, 'ma...   \n",
       "Overall         {'learning_rate': 0.05, 'max_depth': 10, 'max_...   \n",
       "\n",
       "                                                   AdaBoost  \\\n",
       "dataset-of-00s  {'learning_rate': 0.5, 'n_estimators': 100}   \n",
       "dataset-of-10s  {'learning_rate': 1.0, 'n_estimators': 100}   \n",
       "dataset-of-60s  {'learning_rate': 0.5, 'n_estimators': 100}   \n",
       "dataset-of-70s   {'learning_rate': 0.5, 'n_estimators': 50}   \n",
       "dataset-of-80s  {'learning_rate': 0.5, 'n_estimators': 100}   \n",
       "dataset-of-90s   {'learning_rate': 0.5, 'n_estimators': 50}   \n",
       "Overall         {'learning_rate': 1.0, 'n_estimators': 100}   \n",
       "\n",
       "                                               SGD  \\\n",
       "dataset-of-00s    {'alpha': 0.01, 'penalty': 'l1'}   \n",
       "dataset-of-10s    {'alpha': 0.01, 'penalty': 'l1'}   \n",
       "dataset-of-60s  {'alpha': 0.0001, 'penalty': 'l1'}   \n",
       "dataset-of-70s  {'alpha': 0.0001, 'penalty': 'l2'}   \n",
       "dataset-of-80s    {'alpha': 0.01, 'penalty': 'l1'}   \n",
       "dataset-of-90s    {'alpha': 0.01, 'penalty': 'l1'}   \n",
       "Overall          {'alpha': 0.001, 'penalty': 'l2'}   \n",
       "\n",
       "                                             DecisionTree  \n",
       "dataset-of-00s  {'max_depth': 10, 'min_samples_split': 2}  \n",
       "dataset-of-10s  {'max_depth': 10, 'min_samples_split': 5}  \n",
       "dataset-of-60s  {'max_depth': 10, 'min_samples_split': 2}  \n",
       "dataset-of-70s  {'max_depth': 10, 'min_samples_split': 5}  \n",
       "dataset-of-80s  {'max_depth': 10, 'min_samples_split': 2}  \n",
       "dataset-of-90s  {'max_depth': 10, 'min_samples_split': 2}  \n",
       "Overall         {'max_depth': 10, 'min_samples_split': 2}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Best Hyperparameters (5-Fold CV) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>ExtraTrees</th>\n",
       "      <th>GradientBoosting</th>\n",
       "      <th>HistGradientBoosting</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>SGD</th>\n",
       "      <th>DecisionTree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dataset-of-00s</th>\n",
       "      <td>{'max_depth': None, 'min_samples_split': 5, 'n...</td>\n",
       "      <td>{'max_depth': 20, 'min_samples_split': 5, 'n_e...</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 3, 'n_esti...</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': None, 'ma...</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 100}</td>\n",
       "      <td>{'alpha': 0.01, 'penalty': 'l1'}</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-10s</th>\n",
       "      <td>{'max_depth': 20, 'min_samples_split': 5, 'n_e...</td>\n",
       "      <td>{'max_depth': None, 'min_samples_split': 2, 'n...</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 10, 'max_...</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 100}</td>\n",
       "      <td>{'alpha': 0.001, 'penalty': 'l1'}</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-60s</th>\n",
       "      <td>{'max_depth': 20, 'min_samples_split': 2, 'n_e...</td>\n",
       "      <td>{'max_depth': None, 'min_samples_split': 5, 'n...</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 10, 'max_...</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 100}</td>\n",
       "      <td>{'alpha': 0.0001, 'penalty': 'l1'}</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-70s</th>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 5, 'n_e...</td>\n",
       "      <td>{'max_depth': 20, 'min_samples_split': 2, 'n_e...</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': None, 'ma...</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 100}</td>\n",
       "      <td>{'alpha': 0.0001, 'penalty': 'l1'}</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-80s</th>\n",
       "      <td>{'max_depth': None, 'min_samples_split': 5, 'n...</td>\n",
       "      <td>{'max_depth': 20, 'min_samples_split': 2, 'n_e...</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 3, 'n_esti...</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 10, 'max_i...</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 100}</td>\n",
       "      <td>{'alpha': 0.01, 'penalty': 'l1'}</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-90s</th>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 2, 'n_e...</td>\n",
       "      <td>{'max_depth': 20, 'min_samples_split': 2, 'n_e...</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 10, 'max_...</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 100}</td>\n",
       "      <td>{'alpha': 0.0001, 'penalty': 'l1'}</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>{'max_depth': 20, 'min_samples_split': 2, 'n_e...</td>\n",
       "      <td>{'max_depth': None, 'min_samples_split': 2, 'n...</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': None, 'ma...</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 100}</td>\n",
       "      <td>{'alpha': 0.0001, 'penalty': 'l1'}</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 2}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     RandomForest  \\\n",
       "dataset-of-00s  {'max_depth': None, 'min_samples_split': 5, 'n...   \n",
       "dataset-of-10s  {'max_depth': 20, 'min_samples_split': 5, 'n_e...   \n",
       "dataset-of-60s  {'max_depth': 20, 'min_samples_split': 2, 'n_e...   \n",
       "dataset-of-70s  {'max_depth': 10, 'min_samples_split': 5, 'n_e...   \n",
       "dataset-of-80s  {'max_depth': None, 'min_samples_split': 5, 'n...   \n",
       "dataset-of-90s  {'max_depth': 10, 'min_samples_split': 2, 'n_e...   \n",
       "Overall         {'max_depth': 20, 'min_samples_split': 2, 'n_e...   \n",
       "\n",
       "                                                       ExtraTrees  \\\n",
       "dataset-of-00s  {'max_depth': 20, 'min_samples_split': 5, 'n_e...   \n",
       "dataset-of-10s  {'max_depth': None, 'min_samples_split': 2, 'n...   \n",
       "dataset-of-60s  {'max_depth': None, 'min_samples_split': 5, 'n...   \n",
       "dataset-of-70s  {'max_depth': 20, 'min_samples_split': 2, 'n_e...   \n",
       "dataset-of-80s  {'max_depth': 20, 'min_samples_split': 2, 'n_e...   \n",
       "dataset-of-90s  {'max_depth': 20, 'min_samples_split': 2, 'n_e...   \n",
       "Overall         {'max_depth': None, 'min_samples_split': 2, 'n...   \n",
       "\n",
       "                                                 GradientBoosting  \\\n",
       "dataset-of-00s  {'learning_rate': 0.1, 'max_depth': 3, 'n_esti...   \n",
       "dataset-of-10s  {'learning_rate': 0.1, 'max_depth': 5, 'n_esti...   \n",
       "dataset-of-60s  {'learning_rate': 0.05, 'max_depth': 5, 'n_est...   \n",
       "dataset-of-70s  {'learning_rate': 0.1, 'max_depth': 5, 'n_esti...   \n",
       "dataset-of-80s  {'learning_rate': 0.1, 'max_depth': 3, 'n_esti...   \n",
       "dataset-of-90s  {'learning_rate': 0.05, 'max_depth': 3, 'n_est...   \n",
       "Overall         {'learning_rate': 0.1, 'max_depth': 5, 'n_esti...   \n",
       "\n",
       "                                             HistGradientBoosting  \\\n",
       "dataset-of-00s  {'learning_rate': 0.05, 'max_depth': None, 'ma...   \n",
       "dataset-of-10s  {'learning_rate': 0.05, 'max_depth': 10, 'max_...   \n",
       "dataset-of-60s  {'learning_rate': 0.05, 'max_depth': 10, 'max_...   \n",
       "dataset-of-70s  {'learning_rate': 0.05, 'max_depth': None, 'ma...   \n",
       "dataset-of-80s  {'learning_rate': 0.1, 'max_depth': 10, 'max_i...   \n",
       "dataset-of-90s  {'learning_rate': 0.05, 'max_depth': 10, 'max_...   \n",
       "Overall         {'learning_rate': 0.05, 'max_depth': None, 'ma...   \n",
       "\n",
       "                                                   AdaBoost  \\\n",
       "dataset-of-00s  {'learning_rate': 0.5, 'n_estimators': 100}   \n",
       "dataset-of-10s  {'learning_rate': 0.5, 'n_estimators': 100}   \n",
       "dataset-of-60s  {'learning_rate': 0.5, 'n_estimators': 100}   \n",
       "dataset-of-70s  {'learning_rate': 0.5, 'n_estimators': 100}   \n",
       "dataset-of-80s  {'learning_rate': 0.5, 'n_estimators': 100}   \n",
       "dataset-of-90s  {'learning_rate': 0.5, 'n_estimators': 100}   \n",
       "Overall         {'learning_rate': 0.5, 'n_estimators': 100}   \n",
       "\n",
       "                                               SGD  \\\n",
       "dataset-of-00s    {'alpha': 0.01, 'penalty': 'l1'}   \n",
       "dataset-of-10s   {'alpha': 0.001, 'penalty': 'l1'}   \n",
       "dataset-of-60s  {'alpha': 0.0001, 'penalty': 'l1'}   \n",
       "dataset-of-70s  {'alpha': 0.0001, 'penalty': 'l1'}   \n",
       "dataset-of-80s    {'alpha': 0.01, 'penalty': 'l1'}   \n",
       "dataset-of-90s  {'alpha': 0.0001, 'penalty': 'l1'}   \n",
       "Overall         {'alpha': 0.0001, 'penalty': 'l1'}   \n",
       "\n",
       "                                             DecisionTree  \n",
       "dataset-of-00s  {'max_depth': 10, 'min_samples_split': 5}  \n",
       "dataset-of-10s  {'max_depth': 10, 'min_samples_split': 5}  \n",
       "dataset-of-60s  {'max_depth': 10, 'min_samples_split': 2}  \n",
       "dataset-of-70s  {'max_depth': 10, 'min_samples_split': 5}  \n",
       "dataset-of-80s  {'max_depth': 10, 'min_samples_split': 2}  \n",
       "dataset-of-90s  {'max_depth': 10, 'min_samples_split': 2}  \n",
       "Overall         {'max_depth': 10, 'min_samples_split': 2}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Best Hyperparameters (10-Fold CV) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>ExtraTrees</th>\n",
       "      <th>GradientBoosting</th>\n",
       "      <th>HistGradientBoosting</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>SGD</th>\n",
       "      <th>DecisionTree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dataset-of-00s</th>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 5, 'n_e...</td>\n",
       "      <td>{'max_depth': None, 'min_samples_split': 2, 'n...</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 3, 'n_esti...</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': None, 'ma...</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 100}</td>\n",
       "      <td>{'alpha': 0.0001, 'penalty': 'l1'}</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-10s</th>\n",
       "      <td>{'max_depth': None, 'min_samples_split': 5, 'n...</td>\n",
       "      <td>{'max_depth': None, 'min_samples_split': 2, 'n...</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': None, 'ma...</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 100}</td>\n",
       "      <td>{'alpha': 0.0001, 'penalty': 'l1'}</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-60s</th>\n",
       "      <td>{'max_depth': None, 'min_samples_split': 2, 'n...</td>\n",
       "      <td>{'max_depth': None, 'min_samples_split': 2, 'n...</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': None, 'max...</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 100}</td>\n",
       "      <td>{'alpha': 0.001, 'penalty': 'l2'}</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-70s</th>\n",
       "      <td>{'max_depth': 20, 'min_samples_split': 2, 'n_e...</td>\n",
       "      <td>{'max_depth': 20, 'min_samples_split': 2, 'n_e...</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': None, 'ma...</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 100}</td>\n",
       "      <td>{'alpha': 0.0001, 'penalty': 'l2'}</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-80s</th>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 2, 'n_e...</td>\n",
       "      <td>{'max_depth': 20, 'min_samples_split': 2, 'n_e...</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': None, 'max...</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 100}</td>\n",
       "      <td>{'alpha': 0.0001, 'penalty': 'l1'}</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset-of-90s</th>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 2, 'n_e...</td>\n",
       "      <td>{'max_depth': 20, 'min_samples_split': 2, 'n_e...</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': None, 'max...</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 100}</td>\n",
       "      <td>{'alpha': 0.0001, 'penalty': 'l1'}</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>{'max_depth': 20, 'min_samples_split': 2, 'n_e...</td>\n",
       "      <td>{'max_depth': None, 'min_samples_split': 5, 'n...</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 10, 'max_i...</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 100}</td>\n",
       "      <td>{'alpha': 0.001, 'penalty': 'l1'}</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 2}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     RandomForest  \\\n",
       "dataset-of-00s  {'max_depth': 10, 'min_samples_split': 5, 'n_e...   \n",
       "dataset-of-10s  {'max_depth': None, 'min_samples_split': 5, 'n...   \n",
       "dataset-of-60s  {'max_depth': None, 'min_samples_split': 2, 'n...   \n",
       "dataset-of-70s  {'max_depth': 20, 'min_samples_split': 2, 'n_e...   \n",
       "dataset-of-80s  {'max_depth': 10, 'min_samples_split': 2, 'n_e...   \n",
       "dataset-of-90s  {'max_depth': 10, 'min_samples_split': 2, 'n_e...   \n",
       "Overall         {'max_depth': 20, 'min_samples_split': 2, 'n_e...   \n",
       "\n",
       "                                                       ExtraTrees  \\\n",
       "dataset-of-00s  {'max_depth': None, 'min_samples_split': 2, 'n...   \n",
       "dataset-of-10s  {'max_depth': None, 'min_samples_split': 2, 'n...   \n",
       "dataset-of-60s  {'max_depth': None, 'min_samples_split': 2, 'n...   \n",
       "dataset-of-70s  {'max_depth': 20, 'min_samples_split': 2, 'n_e...   \n",
       "dataset-of-80s  {'max_depth': 20, 'min_samples_split': 2, 'n_e...   \n",
       "dataset-of-90s  {'max_depth': 20, 'min_samples_split': 2, 'n_e...   \n",
       "Overall         {'max_depth': None, 'min_samples_split': 5, 'n...   \n",
       "\n",
       "                                                 GradientBoosting  \\\n",
       "dataset-of-00s  {'learning_rate': 0.1, 'max_depth': 3, 'n_esti...   \n",
       "dataset-of-10s  {'learning_rate': 0.1, 'max_depth': 5, 'n_esti...   \n",
       "dataset-of-60s  {'learning_rate': 0.05, 'max_depth': 5, 'n_est...   \n",
       "dataset-of-70s  {'learning_rate': 0.05, 'max_depth': 5, 'n_est...   \n",
       "dataset-of-80s  {'learning_rate': 0.05, 'max_depth': 5, 'n_est...   \n",
       "dataset-of-90s  {'learning_rate': 0.05, 'max_depth': 5, 'n_est...   \n",
       "Overall         {'learning_rate': 0.1, 'max_depth': 5, 'n_esti...   \n",
       "\n",
       "                                             HistGradientBoosting  \\\n",
       "dataset-of-00s  {'learning_rate': 0.05, 'max_depth': None, 'ma...   \n",
       "dataset-of-10s  {'learning_rate': 0.05, 'max_depth': None, 'ma...   \n",
       "dataset-of-60s  {'learning_rate': 0.1, 'max_depth': None, 'max...   \n",
       "dataset-of-70s  {'learning_rate': 0.05, 'max_depth': None, 'ma...   \n",
       "dataset-of-80s  {'learning_rate': 0.1, 'max_depth': None, 'max...   \n",
       "dataset-of-90s  {'learning_rate': 0.1, 'max_depth': None, 'max...   \n",
       "Overall         {'learning_rate': 0.1, 'max_depth': 10, 'max_i...   \n",
       "\n",
       "                                                   AdaBoost  \\\n",
       "dataset-of-00s  {'learning_rate': 0.5, 'n_estimators': 100}   \n",
       "dataset-of-10s  {'learning_rate': 0.5, 'n_estimators': 100}   \n",
       "dataset-of-60s  {'learning_rate': 0.5, 'n_estimators': 100}   \n",
       "dataset-of-70s  {'learning_rate': 0.5, 'n_estimators': 100}   \n",
       "dataset-of-80s  {'learning_rate': 0.5, 'n_estimators': 100}   \n",
       "dataset-of-90s  {'learning_rate': 0.5, 'n_estimators': 100}   \n",
       "Overall         {'learning_rate': 0.5, 'n_estimators': 100}   \n",
       "\n",
       "                                               SGD  \\\n",
       "dataset-of-00s  {'alpha': 0.0001, 'penalty': 'l1'}   \n",
       "dataset-of-10s  {'alpha': 0.0001, 'penalty': 'l1'}   \n",
       "dataset-of-60s   {'alpha': 0.001, 'penalty': 'l2'}   \n",
       "dataset-of-70s  {'alpha': 0.0001, 'penalty': 'l2'}   \n",
       "dataset-of-80s  {'alpha': 0.0001, 'penalty': 'l1'}   \n",
       "dataset-of-90s  {'alpha': 0.0001, 'penalty': 'l1'}   \n",
       "Overall          {'alpha': 0.001, 'penalty': 'l1'}   \n",
       "\n",
       "                                             DecisionTree  \n",
       "dataset-of-00s  {'max_depth': 10, 'min_samples_split': 5}  \n",
       "dataset-of-10s  {'max_depth': 10, 'min_samples_split': 5}  \n",
       "dataset-of-60s  {'max_depth': 10, 'min_samples_split': 5}  \n",
       "dataset-of-70s  {'max_depth': 10, 'min_samples_split': 2}  \n",
       "dataset-of-80s  {'max_depth': 10, 'min_samples_split': 2}  \n",
       "dataset-of-90s  {'max_depth': 10, 'min_samples_split': 2}  \n",
       "Overall         {'max_depth': 10, 'min_samples_split': 2}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hyperparameter tuning complete. Check the tables above for all metrics and bestfound parameters.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    ExtraTreesClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    HistGradientBoostingClassifier,\n",
    "    AdaBoostClassifier,\n",
    ")\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# ----------------------------------------\n",
    "# 0) CONFIGURATION: Update this path\n",
    "# ----------------------------------------\n",
    "data_dir =\"D:\\\\Downloads\\\\archive (9)\"  # < Change this to the folder that holds your CSV files\n",
    "csv_files = sorted(glob.glob(os.path.join(data_dir, \"dataset-of-*.csv\")))\n",
    "if len(csv_files) == 0:\n",
    "    raise ValueError(f\"No files found in {data_dir}. \"\n",
    "                     \"Make sure dataset-of-60s.csv, , dataset-of-10s.csv are present.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 1) FEATURE & TARGET COLUMNS\n",
    "# ----------------------------------------\n",
    "# We include all numeric Spotify audiofeatures & analysis fields:\n",
    "features = [\n",
    "    'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness',\n",
    "    'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo',\n",
    "    'duration_ms', 'time_signature', 'chorus_hit', 'sections'\n",
    "]\n",
    "target_col = 'target'\n",
    "\n",
    "# ----------------------------------------\n",
    "# 2) DEFINE MODELS & THEIR PARAMETER GRIDS\n",
    "# ----------------------------------------\n",
    "model_grids = {\n",
    "    \"RandomForest\": (\n",
    "        RandomForestClassifier(random_state=42),\n",
    "        {\n",
    "            'n_estimators': [100, 200],\n",
    "            'max_depth': [None, 10, 20],\n",
    "            'min_samples_split': [2, 5]\n",
    "        }\n",
    "    ),\n",
    "    \"ExtraTrees\": (\n",
    "        ExtraTreesClassifier(random_state=42),\n",
    "        {\n",
    "            'n_estimators': [100, 200],\n",
    "            'max_depth': [None, 10, 20],\n",
    "            'min_samples_split': [2, 5]\n",
    "        }\n",
    "    ),\n",
    "    \"GradientBoosting\": (\n",
    "        GradientBoostingClassifier(random_state=42),\n",
    "        {\n",
    "            'n_estimators': [100, 200],\n",
    "            'learning_rate': [0.1, 0.05],\n",
    "            'max_depth': [3, 5]\n",
    "        }\n",
    "    ),\n",
    "    \"HistGradientBoosting\": (\n",
    "        HistGradientBoostingClassifier(random_state=42),\n",
    "        {\n",
    "            'learning_rate': [0.1, 0.05],\n",
    "            'max_iter': [100, 200],\n",
    "            'max_depth': [None, 10]\n",
    "        }\n",
    "    ),\n",
    "    \"AdaBoost\": (\n",
    "        AdaBoostClassifier(random_state=42),\n",
    "        {\n",
    "            'n_estimators': [50, 100],\n",
    "            'learning_rate': [1.0, 0.5]\n",
    "        }\n",
    "    ),\n",
    "    \"SGD\": (\n",
    "        SGDClassifier(max_iter=1000, tol=1e-3, random_state=42),\n",
    "        {\n",
    "            'alpha': [1e-4, 1e-3, 1e-2],\n",
    "            'penalty': ['l2', 'l1']\n",
    "        }\n",
    "    ),\n",
    "    \"DecisionTree\": (\n",
    "        DecisionTreeClassifier(random_state=42),\n",
    "        {\n",
    "            'max_depth': [None, 10, 20],\n",
    "            'min_samples_split': [2, 5]\n",
    "        }\n",
    "    )\n",
    "}\n",
    "\n",
    "# ----------------------------------------\n",
    "# 3) STORAGE FOR RESULTS\n",
    "# ----------------------------------------\n",
    "# results[decade][split_type][model_name]  { 'best_params', 'test_accuracy', 'test_f1' }\n",
    "results = {}\n",
    "# cv_results[decade][cv_label][model_name]  { 'best_params', 'mean_cv_f1' }\n",
    "cv_results = {}\n",
    "\n",
    "# ----------------------------------------\n",
    "# 4) HELPERS FOR GRID SEARCH & EVALUATION\n",
    "# ----------------------------------------\n",
    "def tune_and_evaluate_split(X_train, y_train, X_test, y_test, model, param_grid, cv_splits=5):\n",
    "    \"\"\"\n",
    "    Run GridSearchCV on (X_train, y_train) with StratifiedKFold(cv_splits),\n",
    "    optimize for F1, then evaluate on (X_test, y_test).\n",
    "    Returns: (best_params, test_accuracy, test_f1)\n",
    "    \"\"\"\n",
    "    skf = StratifiedKFold(n_splits=cv_splits, shuffle=True, random_state=42)\n",
    "    gs = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=param_grid,\n",
    "        cv=skf,\n",
    "        scoring='f1',\n",
    "        n_jobs=-1,\n",
    "        verbose=0\n",
    "    )\n",
    "    gs.fit(X_train, y_train)\n",
    "    best_clf = gs.best_estimator_\n",
    "    best_params = gs.best_params_\n",
    "    \n",
    "    y_pred = best_clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    return best_params, acc, f1\n",
    "\n",
    "def tune_full_cv(X, y, model, param_grid, cv_splits=5):\n",
    "    \"\"\"\n",
    "    Run GridSearchCV on full (X, y) with StratifiedKFold(cv_splits),\n",
    "    optimize for F1, then return (best_params, mean_cv_f1).\n",
    "    \"\"\"\n",
    "    skf = StratifiedKFold(n_splits=cv_splits, shuffle=True, random_state=42)\n",
    "    gs = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=param_grid,\n",
    "        cv=skf,\n",
    "        scoring='f1',\n",
    "        n_jobs=-1,\n",
    "        verbose=0\n",
    "    )\n",
    "    gs.fit(X, y)\n",
    "    return gs.best_params_, gs.best_score_\n",
    "\n",
    "# ----------------------------------------\n",
    "# 5) PERDECADE HYPERPARAMETER TUNING\n",
    "# ----------------------------------------\n",
    "for file_path in csv_files:\n",
    "    decade_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Keep only numeric features + target, then drop any missing rows\n",
    "    df = df[features + [target_col]].dropna()\n",
    "    X = df[features].values\n",
    "    y = df[target_col].values\n",
    "    \n",
    "    results[decade_name] = {}\n",
    "    cv_results[decade_name] = {}\n",
    "    \n",
    "    # --- 5.1) Two train/test splits: 80/20 and 70/30 ---\n",
    "    for split_label, test_size in [('80/20', 0.20), ('70/30', 0.30)]:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=test_size, stratify=y, random_state=42\n",
    "        )\n",
    "        results[decade_name][split_label] = {}\n",
    "        \n",
    "        for model_name, (base_model, param_grid) in model_grids.items():\n",
    "            best_params, test_acc, test_f1 = tune_and_evaluate_split(\n",
    "                X_train, y_train, X_test, y_test,\n",
    "                base_model, param_grid,\n",
    "                cv_splits=5\n",
    "            )\n",
    "            results[decade_name][split_label][model_name] = {\n",
    "                'best_params': best_params,\n",
    "                'test_accuracy': test_acc,\n",
    "                'test_f1': test_f1\n",
    "            }\n",
    "    \n",
    "    # --- 5.2) Crossvalidation on full decade: 5-fold & 10-fold ---\n",
    "    for cv_label, k in [('CV5', 5), ('CV10', 10)]:\n",
    "        cv_results[decade_name][cv_label] = {}\n",
    "        for model_name, (base_model, param_grid) in model_grids.items():\n",
    "            best_params_full, mean_cv_f1 = tune_full_cv(\n",
    "                X, y,\n",
    "                base_model,\n",
    "                param_grid,\n",
    "                cv_splits=k\n",
    "            )\n",
    "            cv_results[decade_name][cv_label][model_name] = {\n",
    "                'best_params': best_params_full,\n",
    "                'mean_cv_f1': mean_cv_f1\n",
    "            }\n",
    "\n",
    "# ----------------------------------------\n",
    "# 6) OVERALL (ALL DECADES COMBINED) TUNING\n",
    "# ----------------------------------------\n",
    "all_dfs = [pd.read_csv(fp) for fp in csv_files]\n",
    "df_all = pd.concat(all_dfs, ignore_index=True)\n",
    "df_all = df_all[features + [target_col]].dropna()\n",
    "X_all = df_all[features].values\n",
    "y_all = df_all[target_col].values\n",
    "\n",
    "results['Overall'] = {}\n",
    "cv_results['Overall'] = {}\n",
    "\n",
    "# --- 6.1) Two train/test splits on Overall: 80/20 & 70/30 ---\n",
    "for split_label, test_size in [('80/20', 0.20), ('70/30', 0.30)]:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_all, y_all, test_size=test_size, stratify=y_all, random_state=42\n",
    "    )\n",
    "    results['Overall'][split_label] = {}\n",
    "    for model_name, (base_model, param_grid) in model_grids.items():\n",
    "        best_params, test_acc, test_f1 = tune_and_evaluate_split(\n",
    "            X_train, y_train, X_test, y_test,\n",
    "            base_model, param_grid,\n",
    "            cv_splits=5\n",
    "        )\n",
    "        results['Overall'][split_label][model_name] = {\n",
    "            'best_params': best_params,\n",
    "            'test_accuracy': test_acc,\n",
    "            'test_f1': test_f1\n",
    "        }\n",
    "\n",
    "# --- 6.2) Crossvalidation on Overall: 5-fold & 10-fold ---\n",
    "for cv_label, k in [('CV5', 5), ('CV10', 10)]:\n",
    "    cv_results['Overall'][cv_label] = {}\n",
    "    for model_name, (base_model, param_grid) in model_grids.items():\n",
    "        best_params_full, mean_cv_f1 = tune_full_cv(\n",
    "            X_all, y_all, base_model, param_grid, cv_splits=k\n",
    "        )\n",
    "        cv_results['Overall'][cv_label][model_name] = {\n",
    "            'best_params': best_params_full,\n",
    "            'mean_cv_f1': mean_cv_f1\n",
    "        }\n",
    "\n",
    "# ----------------------------------------\n",
    "# 7) SUMMARIZE & DISPLAY ALL RESULTS\n",
    "# ----------------------------------------\n",
    "\n",
    "# Helper to build a DataFrame of a given metric from `results` dictionary:\n",
    "def build_metric_df(results_dict, metric_key, index_labels, split_label):\n",
    "    \"\"\"\n",
    "    results_dict[decade][split_label][model_name][metric_key]\n",
    "    Returns a DataFrame with rows=index_labels, columns=model_names, containing that metric.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for label in index_labels:\n",
    "        row = {m: results_dict[label][split_label][m][metric_key] for m in model_grids}\n",
    "        rows.append(row)\n",
    "    df = pd.DataFrame(rows, index=index_labels, columns=model_grids.keys())\n",
    "    return df\n",
    "\n",
    "# Helper to build a DataFrame of CV metrics from `cv_results` dictionary:\n",
    "def build_cv_df(cv_dict, metric_key, index_labels, cv_label):\n",
    "    \"\"\"\n",
    "    cv_dict[decade][cv_label][model_name][metric_key]\n",
    "    Returns a DataFrame with rows=index_labels, columns=model_names, containing that metric.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for label in index_labels:\n",
    "        row = {m: cv_dict[label][cv_label][m][metric_key] for m in model_grids}\n",
    "        rows.append(row)\n",
    "    df = pd.DataFrame(rows, index=index_labels, columns=model_grids.keys())\n",
    "    return df\n",
    "\n",
    "decade_labels = list(results.keys())  # e.g. ['dataset-of-60s', ..., 'Overall']\n",
    "\n",
    "# 7.1) Test Accuracy & F1 for 80/20 and 70/30\n",
    "acc_80_20 = build_metric_df(results, 'test_accuracy', decade_labels, '80/20')\n",
    "f1_80_20  = build_metric_df(results, 'test_f1', decade_labels, '80/20')\n",
    "\n",
    "acc_70_30 = build_metric_df(results, 'test_accuracy', decade_labels, '70/30')\n",
    "f1_70_30  = build_metric_df(results, 'test_f1', decade_labels, '70/30')\n",
    "\n",
    "print(\"=== Test Accuracy (80/20 Split) ===\")\n",
    "display(acc_80_20)\n",
    "\n",
    "print(\"\\n=== Test F1-Score (80/20 Split) ===\")\n",
    "display(f1_80_20)\n",
    "\n",
    "print(\"\\n=== Test Accuracy (70/30 Split) ===\")\n",
    "display(acc_70_30)\n",
    "\n",
    "print(\"\\n=== Test F1-Score (70/30 Split) ===\")\n",
    "display(f1_70_30)\n",
    "\n",
    "# 7.2) Best Model per Decade for each split (by highest testF1)\n",
    "best_model_80_20 = f1_80_20.idxmax(axis=1)\n",
    "best_model_70_30 = f1_70_30.idxmax(axis=1)\n",
    "\n",
    "print(\"\\n=== Best Model per Decade (80/20) by Test F1 ===\")\n",
    "display(best_model_80_20.to_frame(name=\"Best Model\"))\n",
    "\n",
    "print(\"\\n=== Best Model per Decade (70/30) by Test F1 ===\")\n",
    "display(best_model_70_30.to_frame(name=\"Best Model\"))\n",
    "\n",
    "# 7.3) CrossValidation (mean CV F1) for 5-Fold & 10-Fold\n",
    "cv5_df  = build_cv_df(cv_results, 'mean_cv_f1', decade_labels, 'CV5')\n",
    "cv10_df = build_cv_df(cv_results, 'mean_cv_f1', decade_labels, 'CV10')\n",
    "\n",
    "print(\"\\n=== Mean CV F1 (5-Fold) ===\")\n",
    "display(cv5_df)\n",
    "\n",
    "print(\"\\n=== Mean CV F1 (10-Fold) ===\")\n",
    "display(cv10_df)\n",
    "\n",
    "print(\"\\n=== Best Model per Decade (5-Fold CV) by Mean F1 ===\")\n",
    "display(cv5_df.idxmax(axis=1).to_frame(name=\"Best Model\"))\n",
    "\n",
    "print(\"\\n=== Best Model per Decade (10-Fold CV) by Mean F1 ===\")\n",
    "display(cv10_df.idxmax(axis=1).to_frame(name=\"Best Model\"))\n",
    "\n",
    "# 7.4) Best Hyperparameters for Each Model, Each Decade & Split/CV\n",
    "print(\"\\n=== Best Hyperparameters (80/20 Split) ===\")\n",
    "best_params_80_20 = pd.DataFrame({\n",
    "    decade: {m: results[decade]['80/20'][m]['best_params'] for m in model_grids}\n",
    "    for decade in decade_labels\n",
    "}).T\n",
    "display(best_params_80_20)\n",
    "\n",
    "print(\"\\n=== Best Hyperparameters (70/30 Split) ===\")\n",
    "best_params_70_30 = pd.DataFrame({\n",
    "    decade: {m: results[decade]['70/30'][m]['best_params'] for m in model_grids}\n",
    "    for decade in decade_labels\n",
    "}).T\n",
    "display(best_params_70_30)\n",
    "\n",
    "print(\"\\n=== Best Hyperparameters (5-Fold CV) ===\")\n",
    "best_params_cv5 = pd.DataFrame({\n",
    "    decade: {m: cv_results[decade]['CV5'][m]['best_params'] for m in model_grids}\n",
    "    for decade in decade_labels\n",
    "}).T\n",
    "display(best_params_cv5)\n",
    "\n",
    "print(\"\\n=== Best Hyperparameters (10-Fold CV) ===\")\n",
    "best_params_cv10 = pd.DataFrame({\n",
    "    decade: {m: cv_results[decade]['CV10'][m]['best_params'] for m in model_grids}\n",
    "    for decade in decade_labels\n",
    "}).T\n",
    "display(best_params_cv10)\n",
    "\n",
    "print(\"\\nHyperparameter tuning complete. Check the tables above for all metrics and bestfound parameters.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e178dbd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
